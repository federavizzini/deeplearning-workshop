{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leoilab - Deep learning workshop - Techfestival 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop will take you through training of a deep neural network using Keras. \n",
    "\n",
    "We will train a network to diagnose malignant vs benign melanoma.\n",
    "\n",
    "We'll cover the following topics:\n",
    "* Loading data\n",
    "* Training a basic network\n",
    "* Transfer learning\n",
    "* Adding data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Jupyter Notebooks\n",
    "\n",
    "Cell types:\n",
    "* Markdown cells: Cells like this one with markdown-text in it\n",
    "     - Change highlighted cell to markdown with: `m`\n",
    "* Code cells: Python code cells.\n",
    "    - Change highlighted cell to code with: `y`\n",
    "\n",
    "When highlighting cell:\n",
    "* `shift + enter`: Run cell\n",
    "* `enter`: Enter edit mode in cell\n",
    "* `esc`: Exit edit mode in cell\n",
    "\n",
    "From header above:\n",
    "* `Kernel > Interrupt`: Stop long running cell ( you might need this if running too many epochs ).\n",
    "* `Kernel > Restart`: Restart entire notebook, if it really messes up do this and re-run relevant cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are some helper functions to plot the outputs of our models\n",
    "\n",
    "def plot_training_epochs(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.epoch, history.history['acc'])\n",
    "    plt.plot(history.epoch, history.history['val_acc'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    l = plt.legend(['training accuracy', 'validation accuracy'])\n",
    "\n",
    "def plot_images_with_label(images, labels, class_):\n",
    "    img_to_plot = images[labels[:, class_]==1, ...]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "    for ax, img in zip(axes, img_to_plot):\n",
    "        ax.imshow(array_to_img(img))\n",
    "        ax.axis('off')\n",
    "        \n",
    "def print_confusion_matrix(y_true, y_hat):\n",
    "    return pd.DataFrame(confusion_matrix(y_true, y_hat),\n",
    "                        index=['true_' + cls for cls in classes],\n",
    "                        columns=['pred_' + cls for cls in classes])\n",
    "\n",
    "def rand_by_mask(mask, n=4):\n",
    "    return np.random.choice(np.where(mask)[0], n, replace=False)\n",
    "\n",
    "def rand_by_correct(is_correct, y_true, y_hat, n=4):\n",
    "    return rand_by_mask((y_true == y_hat) == is_correct, n=n)\n",
    "\n",
    "def plot_image_ids(image_ids, generator):\n",
    "    images = np.array(generator.filenames)[image_ids]\n",
    "    print(\"True classes: %s\" % ' '.join(img.split('/')[0] for img in images))\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 10))\n",
    "    for ax, img in zip(axes, images):\n",
    "        image = load_img(path_to_data + '/valid/' + img)\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "\n",
    "def plot_correct_classifications(y_true, y_hat, valid_gen, n=4):\n",
    "    image_ids = rand_by_correct(True, y_true, y_hat, n=n)\n",
    "    print(\"Predictions: %s\" % ' '.join(classes[i] for i in y_hat[image_ids]))\n",
    "    plot_image_ids(image_ids, valid_gen)\n",
    "\n",
    "def plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4):\n",
    "    image_ids = rand_by_correct(False, y_true, y_hat, n=n)\n",
    "    print(\"Predictions: %s\" % ' '.join(classes[i] for i in y_hat[image_ids]))\n",
    "    plot_image_ids(image_ids, valid_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing you need to do is load the data. In the following you can choose:\n",
    "\n",
    "* cat vs dog data: This is nice to use for beginners because it is easy to inspect what happens in each step\n",
    "* ISIC melanoma data: This is harder to classify, and unless you're a dermatologist it's hard to tell the classes apart. But maybe you can get the computer do so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_and_dogs_data = '/home/ubuntu/store/dogscats/1ksample'\n",
    "melanoma_data = '/home/ubuntu/store/isic/1ksample'\n",
    "\n",
    "# Change this to \"cats_and_dogs_data\" to use that dataset instead.\n",
    "path_to_data = cats_and_dogs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some of the things we need from keras\n",
    "from keras.preprocessing.image import ImageDataGenerator          # generator to cycle through images\n",
    "from keras.preprocessing.image import array_to_img                # function to convert arrays back to images \n",
    "from keras.applications.imagenet_utils import preprocess_input    # normalization function for ImageNet\n",
    "from keras.preprocessing.image import load_img                    # function to load image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up some global variables\n",
    "# Batch size is how many images the network looks at at a time\n",
    "batch_size = 16\n",
    "\n",
    "# The image size is what we should scale the images to\n",
    "image_size = (224, 224)\n",
    "\n",
    "# This is the number of classes to classify.\n",
    "#    This is important for what the output of the network should look like.\n",
    "#    In both cases we have two classes (dog/cat) (malignant/benign)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data generators\n",
    "# Create a generator that runs `preprocess_input` on every loaded image.\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Create the training and validation generators.\n",
    "# They use the image sizes, batch sizes, and paths to data set above.\n",
    "print('Load training.')\n",
    "train_gen = data_generator.flow_from_directory(path_to_data + '/train',\n",
    "                                               batch_size=batch_size,\n",
    "                                               target_size=image_size)\n",
    "print('\\nLoad validation.')\n",
    "valid_gen = data_generator.flow_from_directory(path_to_data + '/valid',\n",
    "                                               batch_size=batch_size,\n",
    "                                               target_size=image_size,\n",
    "                                               shuffle=False)\n",
    "\n",
    "# Create a list of classes sorted by index\n",
    "classes = [cls[0] for cls in sorted(train_gen.class_indices.items(), key=lambda e: e[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generators `train_gen` and `test_gen` will iterate over training and testing images. \n",
    "\n",
    "Each output will be a tuple of image-tensor and label-vector.\n",
    "\n",
    "Try plotting the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images here contains a tensor with shape:\n",
    "\n",
    "`(batch_size, image_height, image_width, image_channels)`\n",
    "\n",
    "In our case that is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of labels is a one-hot encoding of the class\n",
    "\n",
    "The dictionary of the class can be seen in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function:\n",
    "\n",
    "`plot_images(images, labels, class)`\n",
    "\n",
    "can plot the images from one of the classes (given the labels). Try plotting both classes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_with_label(images, labels, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a basic network\n",
    "\n",
    "Keras has multiple predefined networks that work well for different tasks under `keras.applications`.\n",
    "\n",
    "They are normally designed to perform on the 1000-class [ImageNet](https://www.image-net.org/) dataset.\n",
    "\n",
    "In our case we only have benign / malignant (or cats vs. dogs), so we need to specify that we want the networks with two instead of a thousand outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create the resnet model\n",
    "model = ResNet50(classes=2, weights=None)\n",
    "\n",
    "# Compile model - don't worry about this :)\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we loaded here has `weights=None`, with this we will randomly initialize the weights of the model.\n",
    "\n",
    "Keras models have methods for doing a bunch of the basic things we might want to do. \n",
    "\n",
    "The resnet model is very big:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model you can run `model.fit_generator`\n",
    "\n",
    "Every time the model has trained once on the training data it will evaluate it's accuracy on the validation data. The resulting training and validation accuracies are printed.\n",
    "\n",
    "When you're done running this you can plot them. \n",
    "\n",
    "Try increasing the number of epochs to run - can you get it to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_epochs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do, when having trained a network is look at performance. We can see how the network does during training above. The orange line is the validation accuracy after each epoch.\n",
    "\n",
    "But let's try and inspect the resulting predictions.\n",
    "\n",
    "We use a confusion matrix, first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some metrics for evaluating the notebook\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = model.predict_generator(valid_gen, verbose=1)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = valid_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %0.4f' % accuracy_score(y_true, y_hat))\n",
    "print('Confusion matrix:')\n",
    "print_confusion_matrix(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot random examples of correctly and incorrectly classified images using the cells below.\n",
    "\n",
    "As they are randomized you can see more examples by rerunning the cells.\n",
    "\n",
    "Is there a pattern to the incorrectly classified examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after a bunch of epochs, the model doesn't really get any better. This might be due to the relatively small data set we're using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "In transfer learning we take a model that was initially trained on one task and use it for another task.\n",
    "\n",
    "All models in `keras.applications` are pre-trained on the 1000 classes in ImageNet, with _a lot_ of data for each class. This means that they can learn the low level representations of objects, and we just need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Load the ResNet model - now with pretrained imagenet weights\n",
    "model_imagenet = ResNet50(weights='imagenet')\n",
    "\n",
    "# Create an output layer with two classes instead of 1000. \n",
    "# The input to that layer should be the second to last layer of the imagenet model.\n",
    "output_layer = Dense(n_classes, activation='softmax')(model_imagenet.layers[-2].output)\n",
    "\n",
    "# Now we can build a new model with our self-defined activation output:\n",
    "model = Model(inputs=model_imagenet.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model will have all layers trainable. We only want to train the layer we added to the top of the model.\n",
    "\n",
    "You can set a layer to be trainable like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If set to `False` it will be untrainable.\n",
    "\n",
    "Set all layers in model to not train, except the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_imagenet.layers[:-1]:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        continue\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model - don't worry about this :)\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try fitting the generator as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              validation_data=valid_gen,\n",
    "                              epochs=2,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_epochs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect results similar to above.\n",
    "\n",
    "Are there any new learnings from the incorrect/correct examples?\n",
    "\n",
    "Try training for longer - how does the train/valid accuracy change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(valid_gen, verbose=1)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = valid_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %0.4f' % accuracy_score(y_true, y_hat))\n",
    "print('Confusion matrix:')\n",
    "print_confusion_matrix(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We see a much better training accuracy then before, but we can also see a bit of overfitting. This is because - when training on the same data multiple times - the model will learn to just remember the data that was shown previously.\n",
    "\n",
    "Since images are very dense with information it is quite easy for this big of a model to remember patterns in each of the images in our data set. To force the model to generalize we can use data augmentation.\n",
    "\n",
    "Data augmentation adds a small random transformation to an image everytime it's loaded (once per epoch).\n",
    "\n",
    "The augmentations we use here are flips, rotations, and zoom.\n",
    "\n",
    "This sure that the model never sees the __exact__ same image twice.\n",
    "\n",
    "Data augmentation is very easy to add in the `ImageDataGenerator` in keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how much data augmentation we want on the images.\n",
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=40.0, # degrees of rotation\n",
    "    zoom_range=0.3\n",
    ")\n",
    "\n",
    "train_gen = data_generator.flow_from_directory(path_to_data + '/train', batch_size=batch_size, target_size=image_size)\n",
    "valid_gen = data_generator.flow_from_directory(path_to_data + '/valid',\n",
    "                                               batch_size=batch_size,\n",
    "                                               target_size=image_size,\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at how the augmented images look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labs = next(train_gen)\n",
    "plt.imshow(array_to_img(imgs[0, ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try training the model again. You can let it run for a while. See how many epochs you need to run before getting to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              validation_data=valid_gen,\n",
    "                              epochs=15,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_epochs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try increasing the amount of training data, remove `1ksample` from the end of `path_to_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(valid_gen, verbose=1)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = valid_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %0.4f' % accuracy_score(y_true, y_hat))\n",
    "print('Confusion matrix:')\n",
    "print_confusion_matrix(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback:\n",
    "\n",
    "Please leave any feedback you migh have in the following text cell - then we'll try to improve our workshop for next time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
