{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leoilab - Deep learning workshop - Techfestival 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop will take you through training of a deep neural network using Keras. \n",
    "\n",
    "We will train a network to diagnose malignant vs benign melanoma.\n",
    "\n",
    "We'll cover the following topics:\n",
    "* Loading data\n",
    "* Training a basic network\n",
    "* Transfer learning\n",
    "* Adding data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Jupyter Notebooks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_epochs(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.epoch, history.history['acc'])\n",
    "    plt.plot(history.epoch, history.history['val_acc'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    l = plt.legend(['training accuracy', 'validation accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_and_dogs_data = '/home/ubuntu/store/dogscats/1ksample'\n",
    "melanoma_data = '/home/ubuntu/store/isic-full/data/'\n",
    "\n",
    "path_to_data = cats_and_dogs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "% matplotlib inline\n",
    "\n",
    "batch_size = 16\n",
    "image_size = (224, 224)\n",
    "n_classes = 2\n",
    "\n",
    "# Create data generators\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_gen = data_generator.flow_from_directory(path_to_data + '/train', batch_size=batch_size, target_size=image_size)\n",
    "valid_gen = data_generator.flow_from_directory(path_to_data + '/valid', batch_size=batch_size, target_size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generators `train_gen` and `test_gen` will iterate over training and testing images. \n",
    "\n",
    "Each output will be a tuple of image-tensor and label-vector.\n",
    "\n",
    "Try plotting the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: try examining the contents of `images` and `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use plt.imshow to plot the images in `images`\n",
    "##       To convert an array back to an image that can be plotted use `array_to_img(image)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the image looks a bit odd. This is because we normalize the three channels of the image to decrease training time (done with the `preprocessing_function` provided above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a basic network\n",
    "\n",
    "Keras has multiple predefined networks that work well for different tasks under `keras.applications`.\n",
    "\n",
    "They are normally designed to perform on the 1000-class [ImageNet](https://www.image-net.org/) dataset.\n",
    "\n",
    "In our case we only have benign / malignant, so we need to specify that we want the networks with two instead of a thousand outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create the resnet model\n",
    "model = ResNet50(classes=2, weights=None)\n",
    "\n",
    "# Compile model - don't worry about this :)\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we loaded here has `weights=None`, with this we will randomly initialize the weights of the model.\n",
    "\n",
    "Keras models have methods for doing a bunch of the basic things we might want to do. \n",
    "\n",
    "Try playing around with the following:\n",
    "\n",
    "* `model.summary`: This will give you a (long) description of the network's layers.\n",
    "\n",
    "* `model.layers`: This will give you a python list of layers, that you can play around with.\n",
    "\n",
    "* `model.predict`: This will apply the model, and output a probability for each class, for each image. Try applying this to the images you got from the generator above.\n",
    "\n",
    "* `model.fit_generator`: This will fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO: run predict on the images from above. You can use np.argmax to get the index with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Run one epoch of training with model.fit_generator.\n",
    "##       You can also supply the argument `validation_data=...` to run validation on a different generator\n",
    "##       Try increasing the number of training cycles (epochs) to 5\n",
    "## TODO: .fit_generator returns a `history`-object.\n",
    "##       Try plotting the train/valid accuracies with `plot_training_epochs(history)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: If you didn't store the history object from running .fit_generator you can get the output from the previous\n",
    "#      cell by typing `_`. The following line will store that output to the history variable. Like this:\n",
    "history = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "In transfer learning we take a model that was initially trained on one task and use it for another task.\n",
    "\n",
    "All models in `keras.applications` are pre-trained on the 1000 classes in ImageNet, with _a lot_ of data for each class. This means that they can learn the low level representations of objects, and we just need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# Load the ResNet model - now with pretrained imagenet weights\n",
    "model_imagenet = ResNet50(weights='imagenet')\n",
    "\n",
    "# Create an output layer with two classes instead of 1000. \n",
    "# The input to that layer should be the second to last layer of the imagenet model.\n",
    "output_layer = Dense(n_classes, activation='softmax')(model_imagenet.layers[-2].output)\n",
    "\n",
    "# Now we can build a new model with our self-defined activation output:\n",
    "model = Model(inputs=model_imagenet.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model will have all layers trainable. We only want to train the layer we added to the top of the model.\n",
    "\n",
    "You can set a layer to be trainable like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If set to `False` it will be untrainable.\n",
    "\n",
    "Set all layers in model to not train, except the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Loop over layers in model.layers and set to not train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model - don't worry about this :)\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try fitting the generator as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: run mode.fit_generator on the data as you did in the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_training_epochs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We see a much better training accuracy then before, but we can also see a bit of overfitting. This is because - when training on the same data multiple times - the model will learn to just remember the data is was shown previously.\n",
    "\n",
    "Since images are very dense with information it is quite easy for this big of a model to remember patterns in each of the images in our data set. To force the model to generalize we can use data augmentation.\n",
    "\n",
    "Data augmentation adds a small random transformation to an image everytime it's loaded (once per epoch).\n",
    "\n",
    "The augmentations we use here are flips, rotations, and zoom.\n",
    "\n",
    "This sure that the model never sees the __exact__ same image twice.\n",
    "\n",
    "Data augmentation is very easy to add in the image data generator in keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=40.0, # degrees of rotation\n",
    "    zoom_range=0.3\n",
    ")\n",
    "\n",
    "train_gen = data_generator.flow_from_directory(path_to_data + '/train', batch_size=batch_size, target_size=image_size)\n",
    "valid_gen = data_generator.flow_from_directory(path_to_data + '/valid', batch_size=batch_size, target_size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at how the augmented images look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labs = next(train_gen)\n",
    "plt.imshow(array_to_img(imgs[0, ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try training the model again. You can let it run for a while. See how many epochs you need to run before getting to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use .fit_generator to train the model again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try increasing the amount of training data, remove `1ksample` from the end of `path_to_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
